{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 1 : Warm-up\n",
    "\n",
    "Ditha Nurcahya Avianty (F1D017016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 Reversed String\n",
    "\n",
    "Obtain the string that arranges letters of the string “stressed” in reverse order (tail to head)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "def reversed_text(text):\n",
    "    return text[::-1]\n",
    "\n",
    "# def reversed_text(text):\n",
    "#     newt = []\n",
    "#     for i in range(len(text)):\n",
    "#         newt.append(text[len(text)-i-1])\n",
    "#     return ''.join(newt)\n",
    "\n",
    "print(reversed_text(\"stressed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 “schooled”\n",
    "\n",
    "Obtain the string that concatenates the 1st, 3rd, 5th, and 7th letters in the string “schooled”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoe\n"
     ]
    }
   ],
   "source": [
    "def take_some(text):\n",
    "    return text[::2]\n",
    "\n",
    "# def take_some(text):\n",
    "#     join_text = []\n",
    "#     for i in range(len(text)):\n",
    "#         if((i+1)%2==1):\n",
    "#             join_text.append(text[i])\n",
    "#     return ''.join(join_text)\n",
    "\n",
    "print(take_some(\"schooled\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. “shoe” + “cold” = “schooled”Permalink\n",
    "\n",
    "Obtain the string “schooled” by concatenating the letters in “shoe” and “cold” one after the other from head to tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schooled\n"
     ]
    }
   ],
   "source": [
    "def joining(text1,text2):\n",
    "    joint = []\n",
    "    for i in range(len(text1)):\n",
    "        joint.append(text1[i])\n",
    "        joint.append(text2[i])\n",
    "    return ''.join(joint)\n",
    "\n",
    "print(joining(\"shoe\",\"cold\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Pi\n",
    "\n",
    "Split the sentence “Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics”. into words, and create a list whose element presents the number of alphabetical letters in the corresponding word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Now': 3, 'I': 1, 'need': 4, 'a': 1, 'drink,': 6, 'alcoholic': 9, 'of': 2, 'course,': 7, 'after': 5, 'the': 3, 'heavy': 5, 'lectures': 8, 'involving': 9, 'quantum': 7, 'mechanics': 9}\n"
     ]
    }
   ],
   "source": [
    "def split_text(text):\n",
    "    char = [\",\",\".\"]\n",
    "    for rep in char:\n",
    "        text_replaced = text.replace(rep,\" \")\n",
    "    return text_replaced.split()\n",
    "\n",
    "text_split = split_text(\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics\")\n",
    "\n",
    "def count_alphabet(listt):\n",
    "    split_count = dict()\n",
    "    for i in listt:\n",
    "        split_count.update({i:len(i)})      \n",
    "    return split_count\n",
    "\n",
    "print(count_alphabet(text_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Atomic symbols\n",
    "\n",
    "Split the sentence “Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can”. into words, and extract the first letter from the 1st, 5th, 6th, 7th, 8th, 9th, 15th, 16th, 19th words and the first two letters from the other words. Create an associative array (dictionary object or mapping object) that maps from the extracted string to the position (offset in the sentence) of the corresponding word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'He', 'Lied', 'Because', 'Boron', 'Could', 'Not', 'Oxidize', 'Fluorine', 'New', 'Nations', 'Might', 'Also', 'Sign', 'Peace', 'Security', 'Clause', 'Arthur', 'King', 'Can']\n",
      "['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mi', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K', 'Ca']\n",
      "\n",
      " {'H': 0, 'He': 1, 'Li': 2, 'Be': 3, 'B': 4, 'C': 5, 'N': 6, 'O': 7, 'F': 8, 'Ne': 9, 'Na': 10, 'Mi': 11, 'Al': 12, 'Si': 13, 'P': 14, 'S': 15, 'Cl': 16, 'Ar': 17, 'K': 18, 'Ca': 19}\n"
     ]
    }
   ],
   "source": [
    "text_split_prob04 = split_text(\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can\")\n",
    "\n",
    "print(text_split_prob04)\n",
    "\n",
    "new_text = []\n",
    "num = [1,5,6,7,8,9,15,16,19]\n",
    "for i in range(len(text_split_prob04)):\n",
    "    if (i+1) in num:\n",
    "        new_text.append(text_split_prob04[i][:1])\n",
    "    else:\n",
    "        new_text.append(text_split_prob04[i][:2])\n",
    "        \n",
    "print(new_text)\n",
    "\n",
    "dict_prob04 = dict()\n",
    "for i in range(len(new_text)):\n",
    "    dict_prob04.update({new_text[i]:i})    \n",
    "    \n",
    "print(\"\\n\",dict_prob04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "\n",
    "Implement a function that obtains n-grams from a given sequence object (e.g., string and list). Use this function to obtain word bi-grams and letter bi-grams from the sentence “I am an NLPer”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word bi-gram [['I', 'am'], ['am', 'an'], ['an', 'NLPer'], ['NLPer']]\n",
      "Letter bi-gram ['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er', 'r']\n"
     ]
    }
   ],
   "source": [
    "def ngram(data,n):\n",
    "    n_gram = []\n",
    "    for i in range(len(data)):\n",
    "        n_gram.append(data[i:i+n])\n",
    "    return n_gram\n",
    "    print(data)\n",
    "    return n_gram\n",
    "\n",
    "data = \"I am an NLPer\"\n",
    "\n",
    "word_data = split_text(data)\n",
    "print(\"Word bi-gram\",ngram(word_data,2))\n",
    "\n",
    "letter_data = data.replace(\" \",\"\")\n",
    "print(\"Letter bi-gram\",ngram(letter_data,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. Set\n",
    "\n",
    "Let the sets of letter bi-grams from the words “paraparaparadise” and “paragraph” $X$ and $Y$, respectively. Obtain the union, intersection, difference of the two sets. In addition, check whether the bigram “se” is included in the sets $X$ and $Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ad', 'di', 'is', 'se', 'e']\n",
      "['pa', 'ar', 'ra', 'ag', 'gr', 'ra', 'ap', 'ph', 'h']\n",
      "\n",
      "Union :  {'is', 'ph', 'ar', 'se', 'pa', 'e', 'gr', 'ad', 'ag', 'ap', 'h', 'di', 'ra'}\n",
      "Intersection :  {'pa', 'ap', 'ra', 'ar'}\n",
      "X - Y :  {'is', 'se', 'e', 'ad', 'di'}\n",
      "Y - X :  {'ag', 'ph', 'gr', 'h'} \n",
      "\n",
      "Bigram se is included in  ['pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ad', 'di', 'is', 'se', 'e']\n",
      "Bigram se is not included in  ['pa', 'ar', 'ra', 'ag', 'gr', 'ra', 'ap', 'ph', 'h']\n"
     ]
    }
   ],
   "source": [
    "X = \"paraparaparadise\"\n",
    "Y = \"paragraph\"\n",
    "\n",
    "bigram_X = ngram(X,2)\n",
    "bigram_Y = ngram(Y,2)\n",
    "\n",
    "print(bigram_X)\n",
    "print(bigram_Y)\n",
    "\n",
    "def calculate_set(X,Y):\n",
    "    X = set(X)\n",
    "    Y = set(Y)\n",
    "    \n",
    "    union = X | Y\n",
    "    intersection = X & Y\n",
    "    diff_xy = X-Y\n",
    "    diff_yx = Y-X\n",
    "    \n",
    "    print(\"\\nUnion : \", union)\n",
    "    print(\"Intersection : \", intersection)\n",
    "    print(\"X - Y : \", diff_xy)\n",
    "    print(\"Y - X : \",diff_yx,\"\\n\")\n",
    "    \n",
    "calculate_set(bigram_X,bigram_Y)\n",
    "\n",
    "def check_bigram(data, check):\n",
    "    if check in data :\n",
    "        print(\"Bigram\",check,\"is included in \",data)\n",
    "    else:\n",
    "        print(\"Bigram\",check,\"is not included in \",data)\n",
    "            \n",
    "check_bigram(bigram_X, \"se\")\n",
    "check_bigram(bigram_Y, \"se\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. Template-based sentence generationPermalink\n",
    "\n",
    "Implement a function that receives arguments, x, y, and z and returns a string “{y} is {z} at {x}”, where “{x}”, “{y}”, and “{z}” denote the values of x, y, and z, respectively. In addition, confirm the return string by giving the arguments x=12, y=\"temperature\", and z=22.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature is 22.4 at 12\n"
     ]
    }
   ],
   "source": [
    "def receive_args(x,y,z):\n",
    "    result = \"{0} is {1} at {2}\".format(y,z,x)\n",
    "    return result\n",
    "    \n",
    "print(receive_args(12,\"temperature\",22.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. cipher text\n",
    "\n",
    "Implement a function cipher that converts a given string with the specification:\n",
    "\n",
    "1. Every alphabetical lowercase letter c is converted to a letter whose ASCII code is (219 - [the ASCII code of c])\n",
    "2. Keep other letters unchanged\n",
    "\n",
    "Use this function to cipher and decipher an English message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U104118 103115114104 117102109120103114108109 103108 120114107115118105 122109119 119118120114107115118105 122109 E109116111114104115 110118104104122116118.\n"
     ]
    }
   ],
   "source": [
    "def cipher_text(data):\n",
    "    result = []\n",
    "    for i in data:\n",
    "        if i.isalpha() and i.islower():\n",
    "            result.append(str(219-ord(i)))\n",
    "        else:\n",
    "            result.append(i)\n",
    "    return \"\".join(result)\n",
    "\n",
    "print(cipher_text(\"Use this function to cipher and decipher an English message.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "\n",
    "Write a program with the specification:\n",
    "\n",
    "1. Receive a word sequence separated by space\n",
    "2. For each word in the sequence:\n",
    "    - If the word is no longer than four letters, keep the word unchanged\n",
    "    - Otherwise,\n",
    "        - Keep the first and last letters unchanged\n",
    "        - Shuffle other letters in other positions (in the middle of the word)\n",
    "\n",
    "Observe the result by giving a sentence, e.g., “I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind “."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'couldn’t', 'believe', 'that', 'I', 'could', 'actually', 'understand', 'what', 'I', 'was', 'reading', ':', 'the', 'phenomenal', 'power', 'of', 'the', 'human', 'mind']\n",
      "['I', 'cudl’ont', 'believe', 'that', 'I', 'cloud', 'aullctay', 'uatrensndd', 'what', 'I', 'was', 'rniedag', ':', 'the', 'pehnaoneml', 'peowr', 'of', 'the', 'human', 'mind']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def shuffle_word(word):\n",
    "    acak = word[1:-1]\n",
    "    \n",
    "#     if()\n",
    "    shuffle = [word[0]] + random.sample(acak, len(acak)) + [word[-1]]\n",
    "    \n",
    "    return \"\".join(shuffle)\n",
    "\n",
    "def typoglycemia(text):\n",
    "    splito = split_text(text)\n",
    "    \n",
    "    print(splito)\n",
    "    typogly = []\n",
    "    for i in splito:\n",
    "        if len(i) > 4:\n",
    "            typogly.append(shuffle_word(i))\n",
    "        else:\n",
    "            typogly.append(i)\n",
    "    return typogly\n",
    "    \n",
    "print(typoglycemia(\"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
